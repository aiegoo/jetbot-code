{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teleoperation\n",
    "\n",
    "In this example we'll control the Jetbot remotely with a gamepad controller connected to our web browser machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create gamepad controller\n",
    "\n",
    "The first thing we want to do is create an instance of the ``Controller`` widget, which we'll use to drive our robot.\n",
    "The ``Controller`` widget takes a ``index`` parameter, which specifies the number of the controller.  This is useful in case you\n",
    "have multiple controllers attached, or some gamepads *appear* as multiple controllers.  To determine the index\n",
    "of the controller you're using,\n",
    "\n",
    "1. Visit [http://html5gamepad.com](http://html5gamepad.com).  \n",
    "2. Press buttons on the gamepad you're using\n",
    "3. Remember the ``index`` of the gamepad that is responding to the button presses\n",
    "\n",
    "Next, we'll create and display our controller using that index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6b69ba93544e06814111bb5152f70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Controller()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets.widgets as widgets\n",
    "\n",
    "controller = widgets.Controller(index=0)  # replace with index of your controller\n",
    "\n",
    "display(controller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if the index is correct, you may see the text ``Connect gamepad and press any button``.  That's because the gamepad hasn't\n",
    "registered with this notebook yet.  Press a button and you should see the gamepad widget appear above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect gamepad controller to robot motors\n",
    "\n",
    "Now, even though we've connected our gamepad, we haven't yet attached the controls to our robot!  The first, and most simple control\n",
    "we want to attach is the motor control.  We'll connect that to the left and right vertical axes using the ``dlink`` function.  The\n",
    "``dlink`` function, unlike the ``link`` function, allows us to attach a transform between the ``source`` and ``target``.  Because\n",
    "the controller axes are flipped from what we think is intuitive for the motor control, we'll use a small *lambda* function to\n",
    "negate the value.\n",
    "\n",
    "> WARNING: This next cell will move the robot if you touch the gamepad controller axes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "import traitlets\n",
    "\n",
    "robot = Robot()\n",
    "\n",
    "left_link = traitlets.dlink((controller.axes[1], 'value'), (robot.left_motor, 'value'), transform=lambda x: -x)\n",
    "right_link = traitlets.dlink((controller.axes[3], 'value'), (robot.right_motor, 'value'), transform=lambda x: -x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Our robot should now respond to our gamepad controller movements.  Now we want to view the live video feed from the camera!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and display Image widget\n",
    "\n",
    "First, let's display an ``Image`` widget that we'll use to show our live camera feed.  We'll set the ``height`` and ``width``\n",
    "to just 300 pixels so it doesn't take up too much space.\n",
    "\n",
    "> FYI: The height and width only effect the rendering on the browser side, not the native image resolution before network transport from robot to browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610c7833d99c42af8de0bb4dbc9ef073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='300', width='300')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = widgets.Image(format='jpeg', width=300, height=300)\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create camera instance\n",
    "\n",
    "Well, right now there's no image presented, because we haven't set the value yet!  We can do this by creating our ``Camera``\n",
    "class and attaching the ``value`` attribute of the camera to the ``value attribute of the image.\n",
    "\n",
    "First, let's create the camera instance, we call the ``instance`` method which will create a new camera\n",
    "if it hasn't been created yet.  If once already exists, this method will return the existing camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Camera\n",
    "\n",
    "camera = Camera.instance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect Camera to Image widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our camera class currently only produces values in BGR8 (blue, green, red, 8bit) format, while our image widget accepts values in compressed *JPEG*.\n",
    "To connect the camera to the image we need to insert the ``bgr8_to_jpeg`` function as a transform in the link.  We do this below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import bgr8_to_jpeg\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see the live video feed shown above!\n",
    "\n",
    "> REMINDER:  You can right click the output of a cell and select ``Create New View for Output`` to display the cell in a separate window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop robot if network disconnects\n",
    "\n",
    "You can drive your robot around by looking through the video feed. But what if your robot disconnects from Wifi?  Well, the motors would keep moving and it would keep trying to stream video and motor commands.  Let's make it so that we stop the robot and unlink the camera and motors when a disconnect occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Heartbeat\n",
    "\n",
    "\n",
    "def handle_heartbeat_status(change):\n",
    "    if change['new'] == Heartbeat.Status.dead:\n",
    "        camera_link.unlink()\n",
    "        left_link.unlink()\n",
    "        right_link.unlink()\n",
    "        robot.stop()\n",
    "\n",
    "heartbeat = Heartbeat(period=0.5)\n",
    "\n",
    "# attach the callback function to heartbeat status\n",
    "heartbeat.observe(handle_heartbeat_status, names='status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the robot disconnects from the internet you'll notice that it stops.  You can then re-connect the camera and motors by re-creating the links with the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only call this if your robot links were unlinked, otherwise we'll have redundant links which will double\n",
    "# the commands transfered\n",
    "\n",
    "left_link = traitlets.dlink((controller.axes[1], 'value'), (robot.left_motor, 'value'), transform=lambda x: -x)\n",
    "right_link = traitlets.dlink((controller.axes[3], 'value'), (robot.right_motor, 'value'), transform=lambda x: -x)\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save snapshots with gamepad button\n",
    "\n",
    "Now, we'd like to be able to save some images from our robot.  Let's make it so the right bumper (index 5) saves a snapshot of the current live image.  We'll save the images in the ``snapshots/`` directory, with a name that is guaranteed to be unique using the ``uuid`` python package.  We use the ``uuid1`` identifier, because this also encodes the date and MAC address which we might want to use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc82aca16ebd41ec8369aa0ce8442c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6b69ba93544e06814111bb5152f70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Controller(axes=(Axis(value=0.0), Axis(value=0.0), Axis(value=0.0), Axis(value=0.0), Axis(value=0.0), Axis(val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import uuid\n",
    "import subprocess\n",
    "\n",
    "subprocess.call(['mkdir', '-p', 'snapshots'])\n",
    "\n",
    "snapshot_image = widgets.Image(format='jpeg', width=300, height=300)\n",
    "\n",
    "def save_snapshot(change):\n",
    "    # save snapshot when button is pressed down\n",
    "    if change['new']:\n",
    "        file_path = 'snapshots/' + str(uuid.uuid1()) + '.jpg'\n",
    "        \n",
    "        # write snapshot to file (we use image value instead of camera because it's already in JPEG format)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(image.value)\n",
    "            \n",
    "        # display snapshot that was saved\n",
    "        snapshot_image.value = image.value\n",
    "\n",
    "\n",
    "controller.buttons[5].observe(save_snapshot, names='value')\n",
    "\n",
    "display(widgets.HBox([image, snapshot_image]))\n",
    "display(controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2, time\n",
    "from jetpot import bgr8_to_jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "That's it for this example, have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(img):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    gray = cv2.GaussianBlur(gray, (7,7),0)\n",
    "    return gray\n",
    "\n",
    "def thresholding(img_gray):\n",
    "    _, img_th = cv2.threshold(img_gray,np.average(img_gray)-40,255,cv2.THRESH_BINARY)\n",
    "    img_th2 = cv2.adaptiveThreshold(img_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,21,15)\n",
    "    img_th3 = np.bitwise_and(img_th, img_th2)\n",
    "    img_th4 = cv2.subtract(img_th2, img_th3)\n",
    "    for i in range(5):\n",
    "        img_th4 = cv2.medianBlur(img_th4, 5)\n",
    "    return img_th4\n",
    "\n",
    "def mask_roi(img_th, roi):\n",
    "    mask = np.zeros_like(img_th)\n",
    "    cv2.fillPoly(mask, np.array([roi], np.int32), 255)\n",
    "    masked_image = cv2.bitwise_and(img_th, mask)\n",
    "    return masked_image\n",
    "\n",
    "def drawContours(img_rgb, contours):\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        cv2.drawContours(img_rgb, [cnt], 0, (255,0,0), 1)\n",
    "    return img_rgb\n",
    "\n",
    "def approximationContour(img, contours, e=0.02):\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        epsilon = e*cv2.arcLength(cnt, True)\n",
    "        approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "        cv2.drawContours(img, [approx], 0, (0,255,255), 2)\n",
    "    return img\n",
    "\n",
    "def rectwithname(img, contours, e=0.02):\n",
    "    result = img.copy()\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        epsilon = e*cv2.arcLength(cnt, True)\n",
    "        approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "        cv2.rectangle(result,(x,y),(x+w,y+h),(255,0,255),2)\n",
    "    return result\n",
    "\n",
    "def find_midptr(contours):\n",
    "    center_ptrs = []\n",
    "    e=0.01\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        center_ptr = [y, x + 0.5*w,]\n",
    "        center_ptrs.append(center_ptr)\n",
    "    center_ptrs = np.array(center_ptrs)\n",
    "    return center_ptrs\n",
    "\n",
    "def find_midlane(center_ptrs, center_image_point):\n",
    "    L2_norm = np.linalg.norm((center_ptrs - center_image_point), axis=1, ord=2)\n",
    "    loc = np.where(L2_norm==L2_norm.min())[0][0]\n",
    "    midlane = center_ptrs[loc]\n",
    "    return midlane\n",
    "\n",
    "def find_degree(center_image_point, midlane):\n",
    "    return 57.2958*np.arctan((midlane[1] - center_image_point[1])/(center_image_point[0] - midlane[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 224\n",
    "height = 224\n",
    "camera = Camera.instance()\n",
    "input_image = widgets.Image(format='jpeg', width=width, height=height)\n",
    "result1 = widgets.Image(format='jpeg', width=width, height=height)\n",
    "result2 = widgets.Image(format='jpeg', width=width, height=height)\n",
    "result3 = widgets.Image(format='jpeg', width=width, height=height)\n",
    "result4 = widgets.Image(format='jpeg', width=width, height=height)\n",
    "image_box = widgets.HBox([input_image, result1, result2, result3, result4], layout=widgets.Layout(align_self='center'))\n",
    "display(image_box)\n",
    "# display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "while True:\n",
    "    img = camera.value\n",
    "    img_gray = preprocessing(img)\n",
    "    img_th = thresholding(img_gray)\n",
    "    roi = [(0, height),(0, height/2-30), (width, height/2-30),(width, height),]\n",
    "    img_roi = mask_roi(img_th, roi)\n",
    "    \n",
    "    kernel = np.ones((5,3),np.uint8)\n",
    "    img_cl = cv2.morphologyEx(img_roi,cv2.MORPH_CLOSE, np.ones((5,5),np.uint8),iterations=4)\n",
    "    img_op = cv2.morphologyEx(img_cl,cv2.MORPH_OPEN, np.ones((5,5),np.uint8),iterations=3)\n",
    "    \n",
    "    cannyed_image = cv2.Canny(img_op, 300, 500)\n",
    "    contours, _ = cv2.findContours(cannyed_image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    img_approx = approximationContour(img, contours, e=0.02)\n",
    "    img_approx_rect = rectwithname(img, contours, e=0.01)  \n",
    "    \n",
    "    center_ptrs = find_midptr(contours)\n",
    "    \n",
    "    center_image_point = [height-1, width/2-1]\n",
    "        \n",
    "    midlane = find_midlane(center_ptrs, center_image_point)\n",
    "    seta = find_degree(center_image_point, midlane)\n",
    "    \n",
    "    cv2.line(img,(int(center_image_point[1]), int(center_image_point[0])),(int(midlane[1]),int(midlane[0])),(0,0,255),3)\n",
    "    cv2.putText(img, f'{seta}', (int(midlane[1]), int(midlane[0])-5), cv2.FONT_HERSHEY_COMPLEX, 0.5,(255, 0, 0), 1)\n",
    "    \n",
    "    result_img1 = img_th\n",
    "    result_img2 = img_cl\n",
    "    result_img3 = img_op\n",
    "    result_img4 = img\n",
    "    \n",
    "    #show results\n",
    "    result_imgs = [result_img1, result_img2, result_img3, result_img4]\n",
    "    result_values = [result1, result2, result3, result4]\n",
    "    for result_img, result_value in zip(result_imgs, result_values):\n",
    "         if len(result_img.shape)==2:\n",
    "             result_img = np.stack((result_img,)*3,2)\n",
    "        result_value.value = bgr8_to_jpeg(result_img)\n",
    "    input_image.value = bgr8_to_jpeg(img_gray)\n",
    "    \n",
    "    if count ==1000:\n",
    "        break\n",
    "    else:\n",
    "        count = count +1\n",
    "         print(count, end='  ')\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
